version: 2.1

dockerhub_auth: &dockerhub_auth
  auth:
    username: $DOCKERHUB_USERNAME
    password: $DOCKERHUB_PASSWORD

deploy_filter: &deploy_filter
  filters:
    branches:
      ignore:
        - /__.*/

commands:
  top_level_install:
    steps:
      - restore_cache:
          keys:
            - top-level-dependencies-{{ checksum "package-lock.json" }}-v2
      - run:
          command: |
            [ -e "node_modules" ] || npm ci
      - save_cache:
          key: top-level-dependencies-{{ checksum "package-lock.json" }}-v2
          paths:
            - node_modules
  form_backend_install:
    steps:
      - restore_cache:
          keys:
            - form-backend-dependencies-{{ checksum "form_backend/package-lock.json" }}-v2
      - run:
          command: |
            [ -e "form_backend/node_modules" ] || (cd form_backend && npm ci)
      - save_cache:
          key: form-backend-dependencies-{{ checksum "form_backend/package-lock.json" }}-v2
          paths:
            - form_backend/node_modules
  server_install:
    steps:
      - restore_cache:
          keys:
            - server-dependencies-{{ checksum "server/package-lock.json" }}-v2
      - run:
          command: |
            [ -e "server/node_modules" ] || (cd server && npm ci)
      - save_cache:
          key: server-dependencies-{{ checksum "server/package-lock.json" }}-v2
          paths:
            - server/node_modules
  client_install:
    steps:
      # need to bust the client package cache on patch changes in addition to package-lock changes
      - run: cksum ./client/patches/* > client-patch-checksums
      - restore_cache:
          keys:
            - client-dependencies-{{ checksum "client/package-lock.json" }}-{{ checksum "client-patch-checksums" }}-v2
      - run:
          command: |
            [ -e "client/node_modules" ] || (cd client && npm ci)
      - save_cache:
          key: client-dependencies-{{ checksum "client/package-lock.json" }}-{{ checksum "client-patch-checksums" }}-v2
          paths:
            - client/node_modules
            - client/.cache/Cypress # path set by CYPRESS_CACHE_FOLDER env var
  run_codecov:
    parameters:
      project:
        type: string
    steps:
      # downloads codecov to ./codecov, checksums, runs in project (assumes matching flag exists in codecov.yml
      - run:
          command: |
            curl -fLso codecov https://codecov.io/bash;
            # TODO either add shasum to the docker image or do checksums some other way
            #VERSION=$(grep -o 'VERSION=\"[0-9\.]*\"' codecov | cut -d'"' -f2);
            #for i in 1 256 512
            #do
            #  shasum -a $i -c --ignore-missing <(curl -s "https://raw.githubusercontent.com/codecov/codecov-bash/${VERSION}/SHA${i}SUM")
            #done
            chmod +x codecov

            echo << parameters.project >>/.coverage/*/coverage-final.json | xargs -n1 ./codecov -f $1 -F << parameters.project >>

jobs:
  static_analysis:
    docker:
      - image: eaadtbs/ib-ci-build:3.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    steps:
      - checkout:
          path: "~/InfoBase"

      - top_level_install
      - form_backend_install
      - server_install
      - client_install

      - restore_cache:
          keys:
            - repo-wide-lint-cache-{{ .Branch }}
            - repo-wide-lint-cache-master
      - run:
          command: npm run eslint
      - save_cache:
          key: repo-wide-lint-cache-{{ .Branch }}
          paths:
            - .eslintcache

      - run:
          command: npm run prettier

      - run:
          command: cd client && npx tsc --noEmit

  test_form_backend:
    docker:
      - image: eaadtbs/ib-ci-build:3.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    steps:
      - checkout:
          path: "~/InfoBase"

      - top_level_install
      - form_backend_install

      - restore_cache:
          keys:
            - form-backend-jest-cache

      - run: (cd form_backend && npm run unit_tests)

      - run: (cd form_backend && npm run end_to_end_tests)

      - run_codecov:
          project: form_backend

      - save_cache:
          key: form-backend-jest-cache
          paths:
            - form_backend/.cache/jest

  cleanup_dev_links:
    docker:
      - image: eaadtbs/ib-ci-mongo:1.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    steps:
      - checkout:
          path: "~/InfoBase"
      - run: ./scripts/ci_scripts/create_envs.sh

      # only let this job run in the true repo
      - run: if [ "$CIRCLE_PROJECT_REPONAME" != "infobase" ]; then circleci-agent step halt; fi

      - run:
          command: git branch -r > ./active-branches

      # Use checksum of branch list to tell if the dev DBs need to be cleaned up
      - restore_cache:
          keys:
            - dev-dbs-clean-for-these-branches--{{ checksum "./active-branches" }}-v2
      - run:
          command: |
            if [ ! -f "./dev-dbs-clean-for-these-branches" ]; then
              ./scripts/ci_scripts/cleanup_dev_dbs.sh
              ./scripts/ci_scripts/cleanup_dev_links.sh
            fi
      - run: touch ./dev-dbs-clean-for-these-branches
      - save_cache:
          key: dev-dbs-clean-for-these-branches--{{ checksum "./active-branches" }}-v2
          paths:
            - ./dev-dbs-clean-for-these-branches

  checkout_and_install:
    docker:
      - image: eaadtbs/ib-ci-build:3.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    resource_class: medium
    steps:
      - checkout:
          path: "~/InfoBase"
      - run: ./scripts/ci_scripts/create_envs.sh

      - top_level_install
      - client_install
      - server_install

      # transpiling the server slightly out of place for this job, not needed till the server deploy step, but
      # the deploy job image isn't guaranteed to have the necessary environment for this
      - restore_cache:
          keys:
            - server-transpiled-build-{{ .Branch }}-{{ .Revision }}-v2
      - run:
          command: |
            [ -f "server/transpiled_build/app.js" ] || (cd server && ./scripts/deploy/build.sh)
      - save_cache:
          paths:
            - server/transpiled_build
          key: server-transpiled-build-{{ .Branch }}-{{ .Revision }}-v2

      - persist_to_workspace:
          root: ./
          paths:
            - ./*

  build_client:
    docker:
      - image: eaadtbs/ib-ci-build:3.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    resource_class: medium
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      # logging memory usage, build job has maxed out the memory available in CircleCI in the past, good to have this around if it does again
      - run:
          command: |
            while true; do
              sleep 5
              echo "====="
              ps -eo pgrp,comm,vsz,rss,%mem,cmd:1000 --sort %mem |\
                awk '{
                  if (NR==1) printf "%10s %20s %10s %10s %5s %s", $1, $2, $3, $4, $5, $6;
                  else printf "%10s %20s %10s %10s %5s", $1, $2, $3/1024, $4/1024, $5;
                  $1=$2=$3=$4=$5="";
                  print $0;
                }'
              echo "====="
            done
          background: true

      - run: ./scripts/ci_scripts/get_bundle_stats_baseline.sh

      - restore_cache:
          keys:
            # the trailing - means CircleCI will use the latest key matching up to that point
            - webpack-caches-v5-{{ .Branch }}-

      - restore_cache:
          keys:
            - prod-build-{{ .Branch }}{{ .Revision }}-v2
      - run:
          command: |
            [ -f "client/$BUILD_DIR/InfoBase/app/app-a11y-en.min.js" ] || (cd client && ./scripts/deploy/build_all.sh -c "half" -m 1536 -o "PROD_SOURCE_MAP STATS $([[ $CIRCLE_BRANCH = master ]] && echo "STATS-BASELINE")")
      - save_cache:
          key: prod-build-{{ .Branch }}-{{ .Revision }}-v2
          paths:
            - client/build

      - save_cache:
          key: webpack-caches-v5-{{ .Branch }}-{{ .Revision }}
          paths:
            - client/node_modules/.cache/webpack
            - client/node_modules/.cache/babel-loader
            - client/.eslintcache

      # TODO persist_to_workspace only works on an allow list basis which is a bother to maintain, currently seems better (if not ideally
      # efficient) to persist everything with specific exclusions of large and unnecessary directories made via rm's in advance
      - run: rm -rf client/node_modules/.cache/webpack

      - persist_to_workspace:
          root: ./
          paths:
            - ./*

  test_client:
    docker:
      - image: eaadtbs/ib-ci-build:3.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      - restore_cache:
          keys:
            - client-jest-cache

      - run: (cd client && npm run unit_tests)

      - run_codecov:
          project: client

      - save_cache:
          key: client-jest-cache
          paths:
            - client/.cache/jest

  test_server:
    docker:
      - image: eaadtbs/ib-ci-mongo:1.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      - restore_cache:
          keys:
            - server-jest-cache

      - run: (cd server && npm run unit_tests)

      - run:
          name: server mongod
          command: (cd server && npm run mongod)
          background: true
      - run:
          name: start_api_server
          command: (cd server && npm run start)
          background: true

      - run: (cd server && npm run snapshot_tests)

      - run_codecov:
          project: server

      - save_cache:
          key: server-jest-cache
          paths:
            - server/.cache/jest

  test_end_to_end:
    docker:
      - image: eaadtbs/ib-ci-cypress:4.0
        <<: *dockerhub_auth
    working_directory: "~/InfoBase"
    parameters:
      batch-count:
        type: integer
        default: 1
      batch-index:
        type: integer
        default: 0
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      - run:
          name: server mongod
          command: (cd server && npm run mongod)
          background: true
      - run: (cd server && npm run populate_db)
      - run:
          name: start_api_server
          command: (cd server && npm run start)
          background: true

      - run: sed -i "s#${CDN_URL}#.#g" ./client/$BUILD_DIR/InfoBase/app/*.js # Replace the CDN_URL instances in the built InfoBase so the tests will get the right files (ie. NOT just test the previous deploy)
      - run: sed -i "s#${CDN_URL}#.#g" ./client/$BUILD_DIR/InfoBase/*.html # Replace the CDN_URL instances in the built InfoBase so the tests will get the right files (ie. NOT just test the previous deploy)
      - run: sed -i "s#hacky_target_text_for_ci_to_replace_with_test_and_deploy_time_api_urls#http://127.0.0.1:1337/graphql#g" ./client/$BUILD_DIR/InfoBase/app/*.js # Replace CI API URL placeholder with local URL so these tests use the local server

      - run:
          name: start_http_server
          command: (cd client && npm run serve:ci)
          background: true

      - run: (cd client && npm run cypress -- -e BATCH_COUNT=<< parameters.batch-count >>,BATCH_INDEX=<< parameters.batch-index >>)

      - run: circleci step halt # held open at this point by the running server, force halt (returns successful)

  deploy_data:
    working_directory: "~/InfoBase"
    docker:
      - image: eaadtbs/ib-ci-mongo:1.0
        <<: *dockerhub_auth
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      # Checksum all files in data dir, used to determine if the database needs to be populated
      - run: cksum ./data/* > data-checksums

      # Use this cached file to tell if the data needs to be loaded to mongodb (if on a new branch or if data has changed)
      - restore_cache:
          keys:
            - data-is-deployed-{{ .Branch }}-{{ checksum "./data-checksums" }}-v2
      - run:
          command: |
            [ -f "./this-data-is-deployed" ] || (cd server && npm run populate_db:remote)
      - run: touch ./this-data-is-deployed
      - save_cache:
          key: data-is-deployed--{{ .Branch }}-{{ checksum "./data-checksums" }}-v2
          paths:
            - ./this-data-is-deployed

  deploy_server:
    working_directory: "~/InfoBase"
    docker:
      - image: google/cloud-sdk:slim
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh

      - run: ./scripts/ci_scripts/authenticate-server-gcloud.sh

      # Checksum all JS files in transpiled_build, used to determine if the function needs to be redeployed
      - run: find ./server/transpiled_build -name "*.js" | xargs cksum > server-checksums

      # Use this cached file to tell if the api needs to be redeployed (if on a new branch, if function code's changed, or if server node modules have changed)
      - restore_cache:
          keys:
            - api-is-deployed-{{ .Branch }}-{{ checksum "./server-checksums" }}-{{ checksum "./server/package-lock.json" }}-v2
      - run:
          command: |
            [ -f "./this-api-is-deployed" ] || (cd server && ./scripts/deploy/ci_deploy_function.sh)
      - run: touch ./this-api-is-deployed
      - save_cache:
          key: api-is-deployed--{{ .Branch }}-{{ checksum "./server-checksums" }}-{{ checksum "./server/package-lock.json" }}-v2
          paths:
            - ./this-api-is-deployed

  deploy_client:
    working_directory: "~/InfoBase"
    docker:
      - image: google/cloud-sdk:slim
    steps:
      - attach_workspace:
          at: ./
      - run: ./scripts/ci_scripts/create_envs.sh
      - run: ./scripts/ci_scripts/authenticate-client-gcloud.sh

      # Replace CI API URL placeholder with branch specific API URL
      - run: sed -i "s#hacky_target_text_for_ci_to_replace_with_test_and_deploy_time_api_urls#https://us-central1-ib-serverless-api-dev.cloudfunctions.net/$CIRCLE_BRANCH/graphql#g" ./client/$BUILD_DIR/InfoBase/app/*.js
      - run: (cd client && ./scripts/deploy/push_to_gcloud_bucket.sh)

      # only saving master stats right now since they're somewhat large files (~1 mb each)
      - run: if [[ $CIRCLE_BRANCH = master ]]; then ./scripts/ci_scripts/store_bundle_stats.sh; fi

workflows:
  static_analysis:
    jobs:
      - static_analysis

  test_form_backend:
    jobs:
      - test_form_backend

  cleanup_dev_links:
    jobs:
      - cleanup_dev_links:
          <<: *deploy_filter

  build_test_deploy:
    jobs:
      - checkout_and_install

      - test_client:
          requires:
            - checkout_and_install
      - build_client:
          requires:
            - test_client

      - test_server:
          requires:
            - checkout_and_install
      - deploy_data:
          requires:
            - test_server
          <<: *deploy_filter
      - deploy_server:
          requires:
            - test_server
          <<: *deploy_filter

      - test_end_to_end:
          requires:
            - test_server
            - build_client
          matrix:
            parameters:
              batch-count: [3]
              batch-index: [0, 1, 2]

      - deploy_client:
          requires:
            - deploy_data
            - deploy_server
            - test_end_to_end
          <<: *deploy_filter
